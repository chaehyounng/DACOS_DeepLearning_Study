{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CH7"
      ],
      "metadata": {
        "id": "lz4Hc4a52Yhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "yegxYeK125MX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.4"
      ],
      "metadata": {
        "id": "OyJbDybs2aKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7-21 단계별 훈련 루프 작성하기: 훈련 스텝 함수"
      ],
      "metadata": {
        "id": "FI8bnTbx3gVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_mnist_model()\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()  # 손실 함수 준비\n",
        "optimizer = keras.optimizers.RMSprop()  # 옵티마이저 준비\n",
        "metrics = [keras.metrics.SparseCategoricalAccuracy()]  # 모니터링할 지표 리스트 준비\n",
        "loss_tracking_metric = keras.metrics.Mean()  # 손실 평균을 추적할 평균 지표 준비\n",
        "\n",
        "def train_step(inputs, targets):\n",
        "  # 정방향 패스를 실행\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs, training=True)\n",
        "    loss = loss_fn(targets, predictions)\n",
        "  # 역방향 패스 실행\n",
        "  gradients = tape.gradient(loss, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "  # 측정 지표 계산\n",
        "  logs = {}\n",
        "  for metric in metrics:\n",
        "    metric.update_state(targets, predictions)\n",
        "    logs[metric.name] = metric.result()\n",
        "  # 손실 평균 계산\n",
        "  loss_tracking_metric.update_state(loss)\n",
        "  logs[\"loss\"] = loss_tracking_metric.result()\n",
        "   # 지표와 손실의 현재 값을 반환\n",
        "  return logs"
      ],
      "metadata": {
        "id": "hgOsfAEk3kyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7-22 단계별 훈련 루프 작성하기: 지표 재설정"
      ],
      "metadata": {
        "id": "WUwmF2My4ywa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_metrics():\n",
        "  for metric in metrics:\n",
        "    metic.reset_state()\n",
        "  loss_tracking_metric.reset_index()"
      ],
      "metadata": {
        "id": "iFMWf_dB47xC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7-23 단계별 훈련 루프 작성하기: 훈련 루프 자체"
      ],
      "metadata": {
        "id": "9fW1rMki5DMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images, train_labels))\n",
        "traing_dataset = training_dataset.batch(32)\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "  reset_metrics()\n",
        "  for inputs_batch, targets_batch in training_dataset:\n",
        "    logs = train_step(inputs_batch, targets_batch)\n",
        "  print(f\"{epoch}번째 에포크 결과\")\n",
        "  for key, value in log.items():\n",
        "    print(f\"...{key}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "_1z99qiL4_cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7-24 단계별 평가 루프 작성하기"
      ],
      "metadata": {
        "id": "-BWBfe1E5rH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(inputs, targets):\n",
        "  predictions = model(inputs, training=False)\n",
        "  loss = loss_fn(targets, predictions)\n",
        "\n",
        "  logs = {}\n",
        "  for metric in metrics:\n",
        "    metric.update_state(targets, predictions)\n",
        "    logs[\"val_\" + metric.name] = metric.result()\n",
        "  loss_tracking_metric.update_state(loss)\n",
        "  logs[\"val_loss\"] = loss_tracking_metric.result()\n",
        "  return logs\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "reset_metrics()\n",
        "for input_batch, targets_batch in val_dataset:\n",
        "  logs = test_stop(inputs_batch, targets_batch)\n",
        "print(\"평가 결과: \")\n",
        "for key, value in logs.items():\n",
        "  print(f\"...{key}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "oChePMlc5toh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7-25 평가 스텝 함수에 @tf.function 데코레이터 추가하기"
      ],
      "metadata": {
        "id": "_0C8PVpm-i9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def test_step(inputs, targets):\n",
        "  predictions = model(inputs, training=False)\n",
        "  loss = loss_fn(targets, predictions)\n",
        "\n",
        "  logs = {}\n",
        "  for metric in metrics:\n",
        "    metric.update_state(targets, predictions)\n",
        "    logs[\"val_\" + metric.name] = metric.result()\n",
        "  loss_tracking_metric.update_state(loss)\n",
        "  logs[\"val_loss\"] = loss_tracking_metric.result()\n",
        "  return logs\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "reset_metrics()\n",
        "for input_batch, targets_batch in val_dataset:\n",
        "  logs = test_stop(inputs_batch, targets_batch)\n",
        "print(\"평가 결과: \")\n",
        "for key, value in logs.items():\n",
        "  print(f\"...{key}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "Bs3rIskm-nA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7-26 fit()이 사용할 사용자 저의 훈련 스텝 구현하기"
      ],
      "metadata": {
        "id": "dB61E6o3-srd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_Fn = keras.losses.SpaseCategorcialCrossentropy()\n",
        "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "  def train_step(self, data):\n",
        "    inputs, targets = data\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self(inputs, training=True)\n",
        "      loss = loss_fn(targets, predictions)\n",
        "    gradients = tape.gradient(loss, self.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
        "    loss_tracker.update_state(loss)\n",
        "    return{\"loss\" : loss_tracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "      return [loss_tracker]"
      ],
      "metadata": {
        "id": "VbdZyjYE-wdw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}